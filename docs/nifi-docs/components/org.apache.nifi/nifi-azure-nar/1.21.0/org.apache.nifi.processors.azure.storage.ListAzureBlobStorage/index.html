<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"></meta><title>ListAzureBlobStorage</title><link rel="stylesheet" href="../../../../../css/component-usage.css" type="text/css"></link></head><script type="text/javascript">window.onload = function(){if(self==top) { document.getElementById('nameHeader').style.display = "inherit"; } }</script><body><h1 id="nameHeader" style="display: none;">ListAzureBlobStorage</h1><h2>Deprecation notice: </h2><p>Processor depends on legacy Microsoft Azure SDK</p><p>Please consider using one the following alternatives: <a href="../org.apache.nifi.processors.azure.storage.ListAzureBlobStorage_v12/index.html">ListAzureBlobStorage_v12</a></p><h2>Description: </h2><p>Lists blobs in an Azure Storage container. Listing details are attached to an empty FlowFile for use with FetchAzureBlobStorage.  This Processor is designed to run on Primary Node only in a cluster. If the primary node changes, the new Primary Node will pick up where the previous node left off without duplicating all of the data.</p><h3>Tags: </h3><p>azure, microsoft, cloud, storage, blob</p><h3>Properties: </h3><p>In the list below, the names of required properties appear in <strong>bold</strong>. Any other properties (not in bold) are considered optional. The table also indicates any default values, and whether a property supports the <a href="../../../../../html/expression-language-guide.html">NiFi Expression Language</a>.</p><table id="properties"><tr><th>Display Name</th><th>API Name</th><th>Default Value</th><th>Allowable Values</th><th>Description</th></tr><tr><td id="name"><strong>Listing Strategy</strong></td><td>listing-strategy</td><td id="default-value">Tracking Timestamps</td><td id="allowable-values"><ul><li>Tracking Timestamps <img src="../../../../../html/images/iconInfo.png" alt="This strategy tracks the latest timestamp of listed entity to determine new/updated entities. Since it only tracks few timestamps, it can manage listing state efficiently. However, any newly added, or updated entity having timestamp older than the tracked latest timestamp can not be picked by this strategy. For example, such situation can happen in a file system if a file with old timestamp is copied or moved into the target directory without its last modified timestamp being updated. Also may miss files when multiple subdirectories are being written at the same time while listing is running." title="This strategy tracks the latest timestamp of listed entity to determine new/updated entities. Since it only tracks few timestamps, it can manage listing state efficiently. However, any newly added, or updated entity having timestamp older than the tracked latest timestamp can not be picked by this strategy. For example, such situation can happen in a file system if a file with old timestamp is copied or moved into the target directory without its last modified timestamp being updated. Also may miss files when multiple subdirectories are being written at the same time while listing is running."></img></li><li>Tracking Entities <img src="../../../../../html/images/iconInfo.png" alt="This strategy tracks information of all the listed entities within the latest 'Entity Tracking Time Window' to determine new/updated entities. This strategy can pick entities having old timestamp that can be missed with 'Tracking Timestamps'. Works even when multiple subdirectories are being written at the same time while listing is running. However additional DistributedMapCache controller service is required and more JVM heap memory is used. See the description of 'Entity Tracking Time Window' property for further details on how it works." title="This strategy tracks information of all the listed entities within the latest 'Entity Tracking Time Window' to determine new/updated entities. This strategy can pick entities having old timestamp that can be missed with 'Tracking Timestamps'. Works even when multiple subdirectories are being written at the same time while listing is running. However additional DistributedMapCache controller service is required and more JVM heap memory is used. See the description of 'Entity Tracking Time Window' property for further details on how it works."></img></li><li>No Tracking <img src="../../../../../html/images/iconInfo.png" alt="This strategy lists an entity without any tracking. The same entity will be listed each time on executing this processor. It is recommended to change the default run schedule value. Any property that related to the persisting state will be disregarded." title="This strategy lists an entity without any tracking. The same entity will be listed each time on executing this processor. It is recommended to change the default run schedule value. Any property that related to the persisting state will be disregarded."></img></li></ul></td><td id="description">Specify how to determine new/updated entities. See each strategy descriptions for detail.</td></tr><tr><td id="name">Record Writer</td><td>record-writer</td><td></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>RecordSetWriterFactory<br/><strong>Implementations: </strong><a href="../../../nifi-scripting-nar/1.21.0/org.apache.nifi.record.script.ScriptedRecordSetWriter/index.html">ScriptedRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.xml.XMLRecordSetWriter/index.html">XMLRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.json.JsonRecordSetWriter/index.html">JsonRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.avro.AvroRecordSetWriter/index.html">AvroRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.csv.CSVRecordSetWriter/index.html">CSVRecordSetWriter</a><br/><a href="../../../nifi-parquet-nar/1.21.0/org.apache.nifi.parquet.ParquetRecordSetWriter/index.html">ParquetRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.text.FreeFormTextRecordSetWriter/index.html">FreeFormTextRecordSetWriter</a><br/><a href="../../../nifi-record-serialization-services-nar/1.21.0/org.apache.nifi.lookup.RecordSetWriterLookup/index.html">RecordSetWriterLookup</a></td><td id="description">Specifies the Record Writer to use for creating the listing. If not specified, one FlowFile will be created for each entity that is listed. If the Record Writer is specified, all entities will be written to a single FlowFile instead of adding attributes to individual FlowFiles.</td></tr><tr><td id="name"><strong>Container Name</strong></td><td>container-name</td><td></td><td id="allowable-values"></td><td id="description">Name of the Azure storage container. In case of PutAzureBlobStorage processor, container can be created if it does not exist.<br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Storage Credentials</td><td>storage-credentials-service</td><td></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>AzureStorageCredentialsService<br/><strong>Implementations: </strong><a href="../org.apache.nifi.services.azure.storage.AzureStorageCredentialsControllerService/index.html">AzureStorageCredentialsControllerService</a><br/><a href="../org.apache.nifi.services.azure.storage.AzureStorageEmulatorCredentialsControllerService/index.html">AzureStorageEmulatorCredentialsControllerService</a><br/><a href="../org.apache.nifi.services.azure.storage.AzureStorageCredentialsControllerServiceLookup/index.html">AzureStorageCredentialsControllerServiceLookup</a></td><td id="description">The Controller Service used to obtain Azure Storage Credentials. Instead of the processor level properties, the credentials can be configured here through a common/shared controller service, which is the preferred way. The 'Lookup' version of the service can also be used to select the credentials dynamically at runtime based on a FlowFile attribute (if the processor has FlowFile input).</td></tr><tr><td id="name">Storage Account Name</td><td>storage-account-name</td><td></td><td id="allowable-values"></td><td id="description">The storage account name. There are certain risks in allowing the account name to be stored as a flowfile attribute. While it does provide for a more flexible flow by allowing the account name to be fetched dynamically from a flowfile attribute, care must be taken to restrict access to the event provenance data (e.g., by strictly controlling the policies governing provenance for this processor). In addition, the provenance repositories may be put on encrypted disk partitions. Instead of defining the Storage Account Name, Storage Account Key and SAS Token properties directly on the processor, the preferred way is to configure them through a controller service specified in the Storage Credentials property. The controller service can provide a common/shared configuration for multiple/all Azure processors. Furthermore, the credentials can also be looked up dynamically with the 'Lookup' version of the service.<br/><strong>Sensitive Property: true</strong><br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Storage Account Key</td><td>storage-account-key</td><td></td><td id="allowable-values"></td><td id="description">The storage account key. This is an admin-like password providing access to every container in this account. It is recommended one uses Shared Access Signature (SAS) token instead for fine-grained control with policies. There are certain risks in allowing the account key to be stored as a flowfile attribute. While it does provide for a more flexible flow by allowing the account key to be fetched dynamically from a flowfile attribute, care must be taken to restrict access to the event provenance data (e.g., by strictly controlling the policies governing provenance for this processor). In addition, the provenance repositories may be put on encrypted disk partitions.<br/><strong>Sensitive Property: true</strong><br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">SAS Token</td><td>storage-sas-token</td><td></td><td id="allowable-values"></td><td id="description">Shared Access Signature token, including the leading '?'. Specify either SAS token (recommended) or Account Key. There are certain risks in allowing the SAS token to be stored as a flowfile attribute. While it does provide for a more flexible flow by allowing the SAS token to be fetched dynamically from a flowfile attribute, care must be taken to restrict access to the event provenance data (e.g., by strictly controlling the policies governing provenance for this processor). In addition, the provenance repositories may be put on encrypted disk partitions.<br/><strong>Sensitive Property: true</strong><br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Common Storage Account Endpoint Suffix</td><td>storage-endpoint-suffix</td><td></td><td id="allowable-values"></td><td id="description">Storage accounts in public Azure always use a common FQDN suffix. Override this endpoint suffix with a different suffix in certain circumstances (like Azure Stack or non-public Azure regions). The preferred way is to configure them through a controller service specified in the Storage Credentials property. The controller service can provide a common/shared configuration for multiple/all Azure processors. Furthermore, the credentials can also be looked up dynamically with the 'Lookup' version of the service.<br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Prefix</td><td>prefix</td><td></td><td id="allowable-values"></td><td id="description">Search prefix for listing<br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Proxy Configuration Service</td><td>proxy-configuration-service</td><td></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>ProxyConfigurationService<br/><strong>Implementation: </strong><a href="../../../nifi-proxy-configuration-nar/1.21.0/org.apache.nifi.proxy.StandardProxyConfigurationService/index.html">StandardProxyConfigurationService</a></td><td id="description">Specifies the Proxy Configuration Controller Service to proxy network requests. Supported proxies: HTTP, SOCKS In case of SOCKS, it is not guaranteed that the selected SOCKS Version will be used by the processor.</td></tr><tr><td id="name">Entity Tracking State Cache</td><td>et-state-cache</td><td></td><td id="allowable-values"><strong>Controller Service API: </strong><br/>DistributedMapCacheClient<br/><strong>Implementations: </strong><a href="../../../nifi-hbase_1_1_2-client-service-nar/1.21.0/org.apache.nifi.hbase.HBase_1_1_2_ClientMapCacheService/index.html">HBase_1_1_2_ClientMapCacheService</a><br/><a href="../../../nifi-distributed-cache-services-nar/1.21.0/org.apache.nifi.distributed.cache.client.DistributedMapCacheClientService/index.html">DistributedMapCacheClientService</a><br/><a href="../../../nifi-redis-nar/1.21.0/org.apache.nifi.redis.service.RedisDistributedMapCacheClientService/index.html">RedisDistributedMapCacheClientService</a><br/><a href="../../../nifi-hazelcast-services-nar/1.21.0/org.apache.nifi.hazelcast.services.cacheclient.HazelcastMapCacheClient/index.html">HazelcastMapCacheClient</a><br/><a href="../../../nifi-couchbase-nar/1.21.0/org.apache.nifi.couchbase.CouchbaseMapCacheClient/index.html">CouchbaseMapCacheClient</a><br/><a href="../../../nifi-hbase_2-client-service-nar/1.21.0/org.apache.nifi.hbase.HBase_2_ClientMapCacheService/index.html">HBase_2_ClientMapCacheService</a><br/><a href="../../../nifi-cassandra-services-nar/1.21.0/org.apache.nifi.controller.cassandra.CassandraDistributedMapCache/index.html">CassandraDistributedMapCache</a></td><td id="description">Listed entities are stored in the specified cache storage so that this processor can resume listing across NiFi restart or in case of primary node change. 'Tracking Entities' strategy require tracking information of all listed entities within the last 'Tracking Time Window'. To support large number of entities, the strategy uses DistributedMapCache instead of managed state. Cache key format is 'ListedEntities::{processorId}(::{nodeId})'. If it tracks per node listed entities, then the optional '::{nodeId}' part is added to manage state separately. E.g. cluster wide cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b', per node cache key = 'ListedEntities::8dda2321-0164-1000-50fa-3042fe7d6a7b::nifi-node3' The stored cache content is Gzipped JSON string. The cache key will be deleted when target listing configuration is changed. Used by 'Tracking Entities' strategy.</td></tr><tr><td id="name">Entity Tracking Time Window</td><td>et-time-window</td><td id="default-value">3 hours</td><td id="allowable-values"></td><td id="description">Specify how long this processor should track already-listed entities. 'Tracking Entities' strategy can pick any entity whose timestamp is inside the specified time window. For example, if set to '30 minutes', any entity having timestamp in recent 30 minutes will be the listing target when this processor runs. A listed entity is considered 'new/updated' and a FlowFile is emitted if one of following condition meets: 1. does not exist in the already-listed entities, 2. has newer timestamp than the cached entity, 3. has different size than the cached entity. If a cached entity's timestamp becomes older than specified time window, that entity will be removed from the cached already-listed entities. Used by 'Tracking Entities' strategy.<br/><strong>Supports Expression Language: true (will be evaluated using variable registry only)</strong></td></tr><tr><td id="name">Entity Tracking Initial Listing Target</td><td>et-initial-listing-target</td><td id="default-value">All Available</td><td id="allowable-values"><ul><li>Tracking Time Window <img src="../../../../../html/images/iconInfo.png" alt="Ignore entities having timestamp older than the specified 'Tracking Time Window' at the initial listing activity." title="Ignore entities having timestamp older than the specified 'Tracking Time Window' at the initial listing activity."></img></li><li>All Available <img src="../../../../../html/images/iconInfo.png" alt="Regardless of entities timestamp, all existing entities will be listed at the initial listing activity." title="Regardless of entities timestamp, all existing entities will be listed at the initial listing activity."></img></li></ul></td><td id="description">Specify how initial listing should be handled. Used by 'Tracking Entities' strategy.</td></tr><tr><td id="name"><strong>Minimum File Age</strong></td><td>Minimum File Age</td><td id="default-value">0 sec</td><td id="allowable-values"></td><td id="description">The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</td></tr><tr><td id="name">Maximum File Age</td><td>Maximum File Age</td><td></td><td id="allowable-values"></td><td id="description">The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</td></tr><tr><td id="name"><strong>Minimum File Size</strong></td><td>Minimum File Size</td><td id="default-value">0 B</td><td id="allowable-values"></td><td id="description">The minimum size that a file must be in order to be pulled</td></tr><tr><td id="name">Maximum File Size</td><td>Maximum File Size</td><td></td><td id="allowable-values"></td><td id="description">The maximum size that a file can be in order to be pulled</td></tr></table><h3>Relationships: </h3><table id="relationships"><tr><th>Name</th><th>Description</th></tr><tr><td>success</td><td>All FlowFiles that are received are routed to success</td></tr></table><h3>Reads Attributes: </h3>None specified.<h3>Writes Attributes: </h3><table id="writes-attributes"><tr><th>Name</th><th>Description</th></tr><tr><td>azure.container</td><td>The name of the Azure container</td></tr><tr><td>azure.blobname</td><td>The name of the Azure blob</td></tr><tr><td>azure.primaryUri</td><td>Primary location for blob content</td></tr><tr><td>azure.secondaryUri</td><td>Secondary location for blob content</td></tr><tr><td>azure.etag</td><td>Etag for the Azure blob</td></tr><tr><td>azure.length</td><td>Length of the blob</td></tr><tr><td>azure.timestamp</td><td>The timestamp in Azure for the blob</td></tr><tr><td>mime.type</td><td>MimeType of the content</td></tr><tr><td>lang</td><td>Language code for the content</td></tr><tr><td>azure.blobtype</td><td>This is the type of blob and can be either page or block type</td></tr></table><h3>State management: </h3><table id="stateful"><tr><th>Scope</th><th>Description</th></tr><tr><td>CLUSTER</td><td>After performing a listing of blobs, the timestamp of the newest blob is stored. This allows the Processor to list only blobs that have been added or modified after this date the next time that the Processor is run.  State is stored across the cluster so that this Processor can be run on Primary Node only and if a new Primary Node is selected, the new node can pick up where the previous node left off, without duplicating the data.</td></tr></table><h3>Restricted: </h3>This component is not restricted.<h3>Input requirement: </h3>This component does not allow an incoming relationship.<h3>System Resource Considerations:</h3>None specified.<h3>See Also:</h3><p><a href="../org.apache.nifi.processors.azure.storage.FetchAzureBlobStorage/index.html">FetchAzureBlobStorage</a>, <a href="../org.apache.nifi.processors.azure.storage.PutAzureBlobStorage/index.html">PutAzureBlobStorage</a>, <a href="../org.apache.nifi.processors.azure.storage.DeleteAzureBlobStorage/index.html">DeleteAzureBlobStorage</a></p></body></html>