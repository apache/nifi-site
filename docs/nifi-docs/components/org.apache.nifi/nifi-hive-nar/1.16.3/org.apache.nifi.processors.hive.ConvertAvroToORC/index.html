<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"></meta><title>ConvertAvroToORC</title><link rel="stylesheet" href="../../../../../css/component-usage.css" type="text/css"></link></head><script type="text/javascript">window.onload = function(){if(self==top) { document.getElementById('nameHeader').style.display = "inherit"; } }</script><body><h1 id="nameHeader" style="display: none;">ConvertAvroToORC</h1><h2>Description: </h2><p>Converts an Avro record into ORC file format. This processor provides a direct mapping of an Avro record to an ORC record, such that the resulting ORC file will have the same hierarchical structure as the Avro document. If an incoming FlowFile contains a stream of multiple Avro records, the resultant FlowFile will contain a ORC file containing all of the Avro records.  If an incoming FlowFile does not contain any records, an empty ORC file is the output. NOTE: Many Avro datatypes (collections, primitives, and unions of primitives, e.g.) can be converted to ORC, but unions of collections and other complex datatypes may not be able to be converted to ORC.</p><h3>Tags: </h3><p>avro, orc, hive, convert</p><h3>Properties: </h3><p>In the list below, the names of required properties appear in <strong>bold</strong>. Any other properties (not in bold) are considered optional. The table also indicates any default values, and whether a property supports the <a href="../../../../../html/expression-language-guide.html">NiFi Expression Language</a>.</p><table id="properties"><tr><th>Name</th><th>Default Value</th><th>Allowable Values</th><th>Description</th></tr><tr><td id="name">ORC Configuration Resources</td><td></td><td id="allowable-values"></td><td id="description">A file or comma separated list of files which contains the ORC configuration (hive-site.xml, e.g.). Without this, Hadoop will search the classpath for a 'hive-site.xml' file or will revert to a default configuration. Please see the ORC documentation for more details.<br/><br/><strong>This property expects a comma-separated list of file resources.</strong><br/></td></tr><tr><td id="name"><strong>Stripe Size</strong></td><td id="default-value">64 MB</td><td id="allowable-values"></td><td id="description">The size of the memory buffer (in bytes) for writing stripes to an ORC file</td></tr><tr><td id="name"><strong>Buffer Size</strong></td><td id="default-value">10 KB</td><td id="allowable-values"></td><td id="description">The maximum size of the memory buffers (in bytes) used for compressing and storing a stripe in memory. This is a hint to the ORC writer, which may choose to use a smaller buffer size based on stripe size and number of columns for efficient stripe writing and memory utilization.</td></tr><tr><td id="name"><strong>Compression Type</strong></td><td id="default-value">NONE</td><td id="allowable-values"><ul><li>NONE</li><li>ZLIB</li><li>SNAPPY</li><li>LZO</li></ul></td><td id="description">No Description Provided.</td></tr><tr><td id="name">Hive Table Name</td><td></td><td id="allowable-values"></td><td id="description">An optional table name to insert into the hive.ddl attribute. The generated DDL can be used by a PutHiveQL processor (presumably after a PutHDFS processor) to create a table backed by the converted ORC file. If this property is not provided, the full name (including namespace) of the incoming Avro record will be normalized and used as the table name.<br/><strong>Supports Expression Language: true (will be evaluated using flow file attributes and variable registry)</strong></td></tr></table><h3>Relationships: </h3><table id="relationships"><tr><th>Name</th><th>Description</th></tr><tr><td>success</td><td>A FlowFile is routed to this relationship after it has been converted to ORC format.</td></tr><tr><td>failure</td><td>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to ORC for any reason</td></tr></table><h3>Reads Attributes: </h3>None specified.<h3>Writes Attributes: </h3><table id="writes-attributes"><tr><th>Name</th><th>Description</th></tr><tr><td>mime.type</td><td>Sets the mime type to application/octet-stream</td></tr><tr><td>filename</td><td>Sets the filename to the existing filename with the extension replaced by / added to by .orc</td></tr><tr><td>record.count</td><td>Sets the number of records in the ORC file.</td></tr><tr><td>hive.ddl</td><td>Creates a partial Hive DDL statement for creating a table in Hive from this ORC file. This can be used in ReplaceText for setting the content to the DDL. To make it valid DDL, add "LOCATION '&lt;path_to_orc_file_in_hdfs&gt;'", where the path is the directory that contains this ORC file on HDFS. For example, ConvertAvroToORC can send flow files to a PutHDFS processor to send the file to HDFS, then to a ReplaceText to set the content to this DDL (plus the LOCATION clause as described), then to PutHiveQL processor to create the table if it doesn't exist.</td></tr></table><h3>State management: </h3>This component does not store state.<h3>Restricted: </h3>This component is not restricted.<h3>Input requirement: </h3>This component requires an incoming relationship.<h3>System Resource Considerations:</h3>None specified.</body></html>